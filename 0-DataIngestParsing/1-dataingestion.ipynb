{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a44d7529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3eac9b",
   "metadata": {},
   "source": [
    "Introduct to Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fed2bd1",
   "metadata": {},
   "source": [
    "### Introduction To Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cafb018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbce99af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup is completed\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import(\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter\n",
    ")\n",
    "print(\"Setup is completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350adbba",
   "metadata": {},
   "source": [
    "## Understanding Document Structure In Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc380dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Structure\n",
      "Content :This is the main text content that will be embedded and searched.\n",
      "Metadata :{'source': 'example.txt', 'page1': 1, 'author': 'John Doe', 'date_created': '2025-10-01', 'custom_data': 'any value'}\n"
     ]
    }
   ],
   "source": [
    "## Create a simple document\n",
    "doc=Document(\n",
    "    page_content=\"This is the main text content that will be embedded and searched.\",\n",
    "    metadata={\n",
    "        \"source\": \"example.txt\",\n",
    "        \"page1\": 1,\n",
    "        \"author\": \"John Doe\",\n",
    "        \"date_created\": \"2025-10-01\",\n",
    "        \"custom_data\":\"any value\"\n",
    "        }\n",
    ")\n",
    "print(\"Document Structure\")\n",
    "\n",
    "print(f\"Content :{doc.page_content}\")\n",
    "print(f\"Metadata :{doc.metadata}\")\n",
    "#print(f\"Content :{doc.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d074ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f24ed5",
   "metadata": {},
   "source": [
    "## Text Files (.txt) - The Simplest Case {#2-text-files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6c0c27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a simple text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c0fac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"data/text_files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469136e9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f0527de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text file is created\n"
     ]
    }
   ],
   "source": [
    "sample_text={\n",
    "    \"data/text_files/Machine_learning.txt\":\"\"\"Machine Learning Basics\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
    "from experience without being explicitly programmed. It focuses on developing computer programs\n",
    "that can access data and use it to learn for themselves.\n",
    "\n",
    "Types of Machine Learning:\n",
    "1. Supervised Learning: Learning with labeled data\n",
    "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
    "3. Reinforcement Learning: Learning through rewards and penalties\n",
    "\n",
    "Applications include image recognition, speech processing, and recommendation systems\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "}\n",
    "for filepath, content in sample_text.items(): \n",
    "    with open(filepath, 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "print(\"Sample text file is created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f412781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 1 document\n",
      "Content Preview: Python Programming Introduction\n",
      "\n",
      "Python is a high-level, interpreted programming language known for its simplicity and readability. Created by Guido van Rossum and first released in 1991, Python has become one of the most popular programming languages in the world.\n",
      "\n",
      "Key Features:\n",
      "\n",
      "Easy to learn and use\n",
      "Extensive standard library\n",
      "Cross-platform compatibility\n",
      "Strong community support\n",
      "Python is widely used in web development, data science, artificial intelligence, and automation.\n",
      "\n",
      "    ...\n",
      "Metadata: {'source': 'data/text_files/python_intro.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "## Loading a single text file\n",
    "loader=TextLoader(\"data/text_files/python_intro.txt\", encoding=\"utf-8\")\n",
    "documents=loader.load()\n",
    "print(f\"loaded {len(documents)} document\")\n",
    "print(f\"Content Preview: {documents[0].page_content[:1000]}...\")\n",
    "print(f\"Metadata: {documents[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177076de",
   "metadata": {},
   "source": [
    "## DirectoryLoader - Multiple Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0894347c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 1448.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 documents\n",
      "\n",
      "Document 1:\n",
      "   Source: data\\text_files\\Machine_learning.txt\n",
      "   Lenth:  574 characters\n",
      "\n",
      "Document 2:\n",
      "   Source: data\\text_files\\machine_learning1.txt\n",
      "   Lenth:  575 characters\n",
      "\n",
      "Document 3:\n",
      "   Source: data\\text_files\\python_intro.txt\n",
      "   Lenth:  487 characters\n",
      "\n",
      "Document 4:\n",
      "   Source: data\\text_files\\python_intro1.txt\n",
      "   Lenth:  489 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "## Load all the text files from the directory\n",
    "dir_loader=DirectoryLoader(\n",
    "    \"data/text_files\",\n",
    "    glob=\"**/*.txt\",  ## Pattern to match files\n",
    "    loader_cls= TextLoader,  ## loader class to use\n",
    "    loader_kwargs={'encoding':'utf-8'},\n",
    "    show_progress=True\n",
    "\n",
    "\n",
    ")\n",
    "documents=dir_loader.load()\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(f\"   Source: {doc.metadata['source']}\")\n",
    "    print(f\"   Lenth:  {len(doc.page_content)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a57a2c",
   "metadata": {},
   "source": [
    "## Text Splitting Statergies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e4d0066",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Different text splitting statergies\n",
    "from langchain.text_splitter import(\n",
    "    CharacterTextSplitter,\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    TokenTextSplitter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed1e9bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine Learning Basics\\n\\nMachine learning is a subset of artificial intelligence that enables systems to learn and improve\\nfrom experience without being explicitly programmed. It focuses on developing computer programs\\nthat can access data and use it to learn for themselves.\\n\\nTypes of Machine Learning:\\n1. Supervised Learning: Learning with labeled data\\n2. Unsupervised Learning: Finding patterns in unlabeled data\\n3. Reinforcement Learning: Learning through rewards and penalties\\n\\nApplications include image recognition, speech processing, and recommendation systems\\n\\n    '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Method 1 - Character text splitter\n",
    "text=documents[0].page_content\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4056bb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHARACTER TEXT SPLITTER\n",
      "Created 4 chunks\n",
      "First chunk: Machine Learning Basics\n",
      "Machine learning is a subset of artificial intelligence that enables systems...\n"
     ]
    }
   ],
   "source": [
    "## Method 1: Character-based splitting\n",
    "print(\"CHARACTER TEXT SPLITTER\")\n",
    "char_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",  # Split on newlines\n",
    "    chunk_size=200,  # Max chunk size in characters\n",
    "    chunk_overlap=20,  # Overlap between chunks\n",
    "    length_function=len  # How to measure chunk size\n",
    ")\n",
    "char_chunks = char_splitter.split_text(text)\n",
    "print(f\"Created {len(char_chunks)} chunks\")\n",
    "print(f\"First chunk: {char_chunks[0][:100]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "623a04d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning Basics\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
      "--------------------\n",
      "from experience without being explicitly programmed. It focuses on developing computer programs\n",
      "that can access data and use it to learn for themselves.\n",
      "Types of Machine Learning:\n",
      "--------------------\n",
      "1. Supervised Learning: Learning with labeled data\n",
      "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
      "3. Reinforcement Learning: Learning through rewards and penalties\n",
      "--------------------\n",
      "Applications include image recognition, speech processing, and recommendation systems\n"
     ]
    }
   ],
   "source": [
    "# Example: print the first two character chunks without errors\n",
    "print(char_chunks[0])\n",
    "print(\"--------------------\")\n",
    "print(char_chunks[1])\n",
    "print(\"--------------------\")\n",
    "print(char_chunks[2])\n",
    "print(\"--------------------\")\n",
    "print(char_chunks[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebb84850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2️⃣ RECURSIVE CHARACTER TEXT SPLITTER\n",
      "Created 4 chunks\n",
      "First chunk: Machine Learning Basics\n",
      "\n",
      "Machine learning is a subset of artificial intelligence that enables system...\n",
      "Machine Learning Basics\n",
      "\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
      "--------------------\n",
      "from experience without being explicitly programmed. It focuses on developing computer programs\n",
      "that can access data and use it to learn for themselves.\n",
      "\n",
      "Types of Machine Learning:\n",
      "--------------------\n",
      "1. Supervised Learning: Learning with labeled data\n",
      "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
      "3. Reinforcement Learning: Learning through rewards and penalties\n",
      "--------------------\n",
      "Applications include image recognition, speech processing, and recommendation systems\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Recursive character splitting (RECOMMENDED)\n",
    "print(\"\\n2️⃣ RECURSIVE CHARACTER TEXT SPLITTER\")\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=['\\n'],  # Try these separators in order\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "recursive_chunks = recursive_splitter.split_text(text)\n",
    "print(f\"Created {len(recursive_chunks)} chunks\")\n",
    "print(f\"First chunk: {recursive_chunks[0][:100]}...\")\n",
    "\n",
    "print(recursive_chunks[0])\n",
    "print(\"--------------------\")\n",
    "print(recursive_chunks[1])\n",
    "print(\"--------------------\")\n",
    "print(recursive_chunks[2])\n",
    "print(\"--------------------\")\n",
    "print(recursive_chunks[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f0040e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3️⃣ TOKEN TEXT SPLITTER\n",
      "Created 3 chunks\n",
      "First chunk: Machine Learning Basics\n",
      "\n",
      "Machine learning is a subset of artificial intelligence that enables system...\n"
     ]
    }
   ],
   "source": [
    "import certifi\n",
    "import os\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "\n",
    "print(\"\\n3️⃣ TOKEN TEXT SPLITTER\")\n",
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size=50,  # Size in tokens (not characters)\n",
    "    chunk_overlap=10,\n",
    ")\n",
    "\n",
    "token_chunks = token_splitter.split_text(text)\n",
    "print(f\"Created {len(token_chunks)} chunks\")\n",
    "print(f\"First chunk: {token_chunks[0][:100]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGUdemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
